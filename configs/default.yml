train:
  epochs: 1000
  batch_size: 5
  mode: as
  seed: 0

  wandb_project_name: MetaformerGNN
  wandb_run_name: run_1
  wandb_mode: online
  wandb_log_steps: 1 # Log every n steps
  wandb_group_name: debug # bunch multiple runs into a group
  wandb_entity: nimako 
  use_wandb: False

  optimizer:
    lr: 0.001
    weight_decay: 0.00001

  scheduler:
    patience: 10
    threshold: 0.01
    min_lr: 0.0000001

  criterion:
    classification_lambda: 1

  evaluator:
    standards: ["acc", "mae"] # Can include mae, r2, f1, acc
    eval_metric: mae # Must be one of values specified in standards
    maximize: False

model:
  checkpoint_path: # Must be specified for testing. Optional for training.
  num_classes: 4
  sub_models:
    - backbone  
    - gnn
    - pc
  backbone:
    pretrained: True
    embedding_size: 128

  gnn:
    channel_list: [256, 64, 16]
    num_classes: 4
    # the length of heads must be one item smaller than the channels list
    heads: [4, 4]
    do_prob: 0.5
  pc:
    in_channels: 6
    out_channels: 128
    num_layers: 4
    hidden_dim: 256
    num_heads: 8
    dropout: 0.1

data:
  name: as # as|echonet|biplane
  dataset_path: /mnt/data/
  # dataset_filename: annotations-all.csv
  # dataset_path: /arc/project/st-puranga-1/datasets/aortic-stenonsis/round2
  frame_size: 224
  max_frames: 32 # Number of samples prior to subsampling
  n_sampled_frames: 32 # Number of frame to subsample
  max_clips: 4 # Number of back to back clips to extract per video
  mean: 0.0857377 # for echonet: 0.1292275 | for AS: 0.0857377
  std: 0.1708384 # for echonet: 0.1902375 | for AS: 0.1708384
  use_metadata: True
gpu: 0